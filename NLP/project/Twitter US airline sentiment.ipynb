{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/manjusri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manjusri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/manjusri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk import ToktokTokenizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Tweets.csv\n",
    "tweets = pd.read_csv('Tweets.csv')\n",
    "# Set max_colwidth so we can see the entire text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Displaying 5 rows\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insigths:\n",
    "\n",
    "`The dataset has several columns. Some of the columns has NaN values. It seems we don't need all these columns to do\n",
    "the sentiment analysis, for example tweet_created time, tweet_location doesn't impact the sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 15)\n"
     ]
    }
   ],
   "source": [
    "# Displaying the dataset shape\n",
    "print(tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insigths:\n",
    "\n",
    "`The dataset has 14640 tweets with 15 columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14640.00000</td>\n",
       "      <td>14640.00000</td>\n",
       "      <td>10522.00000</td>\n",
       "      <td>14640.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>569218351767499200.00000</td>\n",
       "      <td>0.90017</td>\n",
       "      <td>0.63830</td>\n",
       "      <td>0.08265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>779111158481835.87500</td>\n",
       "      <td>0.16283</td>\n",
       "      <td>0.33044</td>\n",
       "      <td>0.74578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>567588278875213824.00000</td>\n",
       "      <td>0.33500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>568559178101439488.00000</td>\n",
       "      <td>0.69230</td>\n",
       "      <td>0.36060</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>569477857923110912.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.67060</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>569890473289000960.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>570310600460525568.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>44.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tweet_id airline_sentiment_confidence  \\\n",
       "count               14640.00000                  14640.00000   \n",
       "mean   569218351767499200.00000                      0.90017   \n",
       "std       779111158481835.87500                      0.16283   \n",
       "min    567588278875213824.00000                      0.33500   \n",
       "25%    568559178101439488.00000                      0.69230   \n",
       "50%    569477857923110912.00000                      1.00000   \n",
       "75%    569890473289000960.00000                      1.00000   \n",
       "max    570310600460525568.00000                      1.00000   \n",
       "\n",
       "      negativereason_confidence retweet_count  \n",
       "count               10522.00000   14640.00000  \n",
       "mean                    0.63830       0.08265  \n",
       "std                     0.33044       0.74578  \n",
       "min                     0.00000       0.00000  \n",
       "25%                     0.36060       0.00000  \n",
       "50%                     0.67060       0.00000  \n",
       "75%                     1.00000       0.00000  \n",
       "max                     1.00000      44.00000  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data description\n",
    "tweets.describe().apply(lambda s: s.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand of data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the columns in the dataset\n",
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all the columns except 'text' and 'airline_sentiment' and updating the tweets dataset using inplace=True\n",
    "tweets.drop(tweets.columns.difference(['text', 'airline_sentiment']), axis=1, inplace=True)\n",
    "# Displaying the shape of the dataset after removing other columns\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insigths:\n",
    "\n",
    "`The dataset now has 14640 tweets with 2 columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                             text  \n",
       "0                                                                                             @VirginAmerica What @dhepburn said.  \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!  \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the 5 rows after removing the other columns data\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "`airline_sentiment column has the classes like negative, neutral and positive hence its our target column`\n",
    "\n",
    "`The text column has text with special characters, html codes.. etc. we need to clean the text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting count plot of airline_sentiment\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(tweets['airline_sentiment'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "`The dataset has tweets with negative sentiment more`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica it\\'s really aggressive to blast obnoxious \"entertainment\" in your guests\\' faces &amp; they have little recourse'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a sample tweet from the dataset so that we can verify the output of each preprocessing function\n",
    "sample_tweet= tweets['text'][3]\n",
    "sample_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insigths:\n",
    "\n",
    "`The text has special characters like @, \" and has contractions (It's, guests'). It also has html code &amp;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove html tags in the text.\n",
    "# The function uses BeautifulSoup to remove the html tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica it\\'s really aggressive to blast obnoxious \"entertainment\" in your guests\\' faces & they have little recourse'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing html tags from the sample tweet and updating it\n",
    "sample_tweet = remove_html_tags(sample_tweet)\n",
    "sample_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insigths:\n",
    "\n",
    "`remove_html_tags removed the html code &amp; from sample tweet text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create tokens from a given text. Uses ToktokTokenizer from nltk library\n",
    "def tokenize(text):\n",
    "    toktok = ToktokTokenizer()\n",
    "    # Overridding toktok instance fields as the default one is converting & to amp. \n",
    "    # The following code overrides that behaviour\n",
    "    toktok.AMPERCENT = re.compile('& '), '& '\n",
    "    toktok.TOKTOK_REGEXES = [(regex, sub) if sub != '&amp; ' else (re.compile('& '), '& ') for (regex, sub) in\n",
    "                            ToktokTokenizer.TOKTOK_REGEXES]\n",
    "\n",
    "    tokens = toktok.tokenize(text)\n",
    "    return [token.strip() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@VirginAmerica', 'it', \"'\", 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '\"', 'entertainment', '\"', 'in', 'your', 'guests', \"'\", 'faces', '&', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing sample tweet and creating sample_tweet_tokens list\n",
    "sample_tweet_tokens = tokenize(sample_tweet)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`We can see it tokenized the entire sentense in to a list of words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers, uses regular expression to replace numbers with empty string\n",
    "def remove_numbers(tokens):\n",
    "    return [re.sub(r'\\d+', '', token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@VirginAmerica', 'it', \"'\", 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '\"', 'entertainment', '\"', 'in', 'your', 'guests', \"'\", 'faces', '&', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Removing numbers if present in the sample tweet tokens\n",
    "sample_tweet_tokens = remove_numbers(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`There is no change to the tokens list as there are no numbers present in the given list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform accented characters if any in to closest english characters\n",
    "def transform_accented_chars(tokens):\n",
    "    return [unicodedata.normalize('NFKD', token).encode('ascii', 'ignore').decode('utf-8', 'ignore') for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@VirginAmerica', 'it', \"'\", 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '\"', 'entertainment', '\"', 'in', 'your', 'guests', \"'\", 'faces', '&', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Transforming accented characters if any in the sample tweet tokens array\n",
    "sample_tweet_tokens = transform_accented_chars(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`There is no change to the tokens list as there are no accented characters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove special characters, uses regular expression to replace special characters with empty string\n",
    "def remove_special_chars(tokens):\n",
    "    return [re.sub(r'[^a-zA-z\\s]', '', token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VirginAmerica', 'it', '', 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '', 'entertainment', '', 'in', 'your', 'guests', '', 'faces', '', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Removing special characters from sample tweet tokens\n",
    "sample_tweet_tokens = remove_special_chars(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`It replaced special characters with empty string. For instance @VirginAmerica is converted to VirginAmerica by removing the special character @`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuations, uses regular expression to remove punctuations \n",
    "def remove_punctuations(tokens):\n",
    "    return [re.sub(r'[^\\w\\s]','', token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VirginAmerica', 'it', '', 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '', 'entertainment', '', 'in', 'your', 'guests', '', 'faces', '', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Removing punctuations from sample tweet tokens list\n",
    "sample_tweet_tokens = remove_punctuations(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`There is no change to the tokens list as there are no punctuations present in the list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace contractions, uses contractions library\n",
    "def replace_contractions(tokens):\n",
    "    return [contractions.fix(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VirginAmerica', 'it', '', 's', 'really', 'aggressive', 'to', 'blast', 'obnoxious', '', 'entertainment', '', 'in', 'your', 'guests', '', 'faces', '', 'they', 'have', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Replacing contractions from sample tweet tokens list\n",
    "sample_tweet_tokens = replace_contractions(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`There is no change to the tokens list as there are no contractions present in the list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords. \n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    list_of_words_to_keep = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
    "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
    "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "    # Removing the above list of words the stop words list so that we can keep these words in the original tokens/text\n",
    "    stop_words = list(set(stop_words) - set(list_of_words_to_keep))\n",
    "    return [token for token in tokens if token not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VirginAmerica', '', 'really', 'aggressive', 'blast', 'obnoxious', '', 'entertainment', '', 'guests', '', 'faces', '', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words from sample tweet tokens list\n",
    "sample_tweet_tokens = remove_stop_words(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`The sample_tweet_tokens list is shrinked as we removed the stop words like it, s, to, in, your..etc from the list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the text to lower case\n",
    "def to_lower(tokens):\n",
    "    return [token.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['virginamerica', '', 'really', 'aggressive', 'blast', 'obnoxious', '', 'entertainment', '', 'guests', '', 'faces', '', 'little', 'recourse']\n"
     ]
    }
   ],
   "source": [
    "# converting the sample tweet tokens into lower case letters\n",
    "sample_tweet_tokens = to_lower(sample_tweet_tokens)\n",
    "print(sample_tweet_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`The tokens in sample_tweet_tokens list are now lowercase words.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Lemmatization\n",
    "def perform_lemmatization(tokens):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica really aggressive blast obnoxious entertainment guest face little recourse'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing the sample tweet tokens and joining the tokens to form a sentence. \n",
    "# While joining we eliminated tokens that are just spaces using filter function\n",
    "sample_tweet_tokens = perform_lemmatization(sample_tweet_tokens)\n",
    "' '.join(filter(None, sample_tweet_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insigths:\n",
    "\n",
    "`Lemmatization converted the tokens into base words. for example guests and faces are converted to guest and face respectively`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A consolidated text preprocessing function which calls all the above pre processing functions for every text in the\n",
    "# tweets dataframe.\n",
    "def preprocess(df):\n",
    "    tweets = df['text']\n",
    "    # create an empty list to hold the pre-processed text\n",
    "    preprocessed_text = []\n",
    "    # loop through every tweet in the dataframe\n",
    "    for tweet in tweets:\n",
    "        # remove html tags from tweet\n",
    "        tweet = remove_html_tags(tweet)\n",
    "        # tokenize the tweet\n",
    "        tokens = tokenize(tweet)\n",
    "        # transform the accented characters\n",
    "        tokens = transform_accented_chars(tokens)\n",
    "        # remove numbers from tokens\n",
    "        tokens = remove_numbers(tokens)\n",
    "        # remove special characters from tokens\n",
    "        tokens = remove_special_chars(tokens)\n",
    "        # remove punctuations from tokens\n",
    "        tokens = remove_punctuations(tokens)\n",
    "        # replace contractions from tokens\n",
    "        tokens = replace_contractions(tokens)\n",
    "        # remove stopwords from tokens\n",
    "        tokens = remove_stop_words(tokens)\n",
    "        # convert tokens to lowercase\n",
    "        tokens = to_lower(tokens)\n",
    "        # perform lemmatization of tokens\n",
    "        tokens = perform_lemmatization(tokens)\n",
    "        # join the tokens to form the sentence back, filter the tokens that are just empty spaces\n",
    "        text = ' '.join(filter(None,tokens))\n",
    "        # add the pre processed or cleansed text to preprocessed_text list\n",
    "        preprocessed_text.append(text)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virginamerica what dhepburn said',\n",
       " 'virginamerica plus added commercial experience tacky',\n",
       " 'virginamerica i didn today must mean i need take another trip',\n",
       " 'virginamerica really aggressive blast obnoxious entertainment guest face little recourse',\n",
       " 'virginamerica really big bad thing']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking preprocess function to process all tweets\n",
    "preprocessed_tweets = preprocess(tweets)\n",
    "# Displaying first 5 tweets after pre processing\n",
    "preprocessed_tweets[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original tweet text\n",
    "<p>@VirginAmerica What @dhepburn said.</p>\n",
    "<p>@VirginAmerica plus you've added commercials to the experience... tacky.</p>\n",
    "<p>@VirginAmerica I didn't today... Must mean I need to take another trip!</p>\n",
    "<p>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</p>\n",
    "<p>@VirginAmerica and it's a really big bad thing about it</p>\n",
    "\n",
    "##### Pre-processed tweet text\n",
    "<p>virginamerica what dhepburn said</p>\n",
    "<p>virginamerica plus added commercial experience tacky</p>\n",
    "<p>virginamerica i didn today must mean i need take another trip</p>\n",
    "<p>virginamerica really aggressive blast obnoxious entertainment guest face little recourse</p>\n",
    "<p>virginamerica really big bad thing</p>\n",
    "\n",
    "### Insights:\n",
    "<ol>\n",
    "    <li> The preprocessing removed special characters like <b>@, ..., \", \" </b>..etc. It also removed html codes like <b>& amp;</b></li>\n",
    "    <li> The preprocessing removed stop words like <b>It's, you've</b>..etc</li>\n",
    "    <li> Data preprocessing removed punctuations like <b>'!'</b>.</li>\n",
    "    <li> Proceprocessing converted every text into lowercase</li>\n",
    "    <li> The preprocessing converted the words into root form by using lemmatization. For instance,  <b>guests faces </b>got converted to <b>guest face</b></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vecrtorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the text into numerical values using CountVectorizer\n",
    "def count_vectorize(data):\n",
    "    # instantiate CountVectorizer instance with max_features = 1000\n",
    "    vectorizer = CountVectorizer(max_features=1000)\n",
    "    # fit and transform the data\n",
    "    vectorized_features = vectorizer.fit_transform(data)\n",
    "    # convert the data to an array and return\n",
    "    return vectorized_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the text into numerical values using TfidfVectorizer\n",
    "def tfidf_vectorize(data):\n",
    "    # instantiate TfidfVectorizer instance with max_features = 1000\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    # fit and transform the data\n",
    "    vectorized_features = vectorizer.fit_transform(data)\n",
    "    # convert the data to an array and return\n",
    "    return vectorized_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting preprocessed tweets into numerical values using CountVectorizer\n",
    "count_vectorized_tweets = count_vectorize(preprocessed_tweets)\n",
    "# Displaying the count vector\n",
    "count_vectorized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape after count vectorization\n",
    "count_vectorized_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "`After count vectorization, we have 14640 rows with 1000 features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first row\n",
    "count_vectorized_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "`The count vector is a matrix of values 0 and 1 depending upon the word occurance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting preprocessed tweets in to numerical values using TfidfVectorizer\n",
    "tfidf_vectorized_tweets = tfidf_vectorize(preprocessed_tweets)\n",
    "# Displaying the tfidf vector\n",
    "tfidf_vectorized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the shape after tfidf vectorization\n",
    "tfidf_vectorized_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`After tfidf vectorization, we have 14640 rows with 1000 features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.63328694, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.50793849, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.58390593, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first row\n",
    "tfidf_vectorized_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "\n",
    "`The tfidf vector is a matrix of values between 0 and 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evalute Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning airline_sentiment data to y as dependent variable\n",
    "y = tweets['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting y from text to numbers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text  label\n",
       "0   neutral      1\n",
       "1  positive      2\n",
       "2   neutral      1\n",
       "3  negative      0\n",
       "4  negative      0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe to display the text sentiment and the corresponding label encoder\n",
    "sentiment_text_vs_label = pd.DataFrame(columns=['text', 'label'])\n",
    "sentiment_text_vs_label['text'] = tweets['airline_sentiment'][0:5]\n",
    "sentiment_text_vs_label['label'] = y[0:5]\n",
    "sentiment_text_vs_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "`The labelencoder mapped the sentiments as below `\n",
    " <ol>\n",
    "    <li>negative --> 0</li>\n",
    "    <li>neutral --> 1</li>\n",
    "    <li>positive --> 2</li>\n",
    " </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function splits the given X and y data into X_train, X_val, X_test, y_train, y_val, y_test and returns them\n",
    "def split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.3, random_state=7)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct list of machine learning classification models that we are going to evaluate.\n",
    "def construct_models_list():\n",
    "    models = [\n",
    "        # Since its a multiclass problem using multi_class='multinomial', solver='lbfgs' for logistic regression\n",
    "        {'model': LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=7), 'name': 'Logistic Regressor'},\n",
    "        {'model': DecisionTreeClassifier(max_depth=7, random_state=7), 'name': 'DecisionTree Classifier'},\n",
    "        {'model': RandomForestClassifier(n_estimators=100, \n",
    "                                         criterion='entropy',\n",
    "                                         max_features='auto',\n",
    "                                         max_depth=7, \n",
    "                                         n_jobs=4, \n",
    "                                         random_state=7), 'name': 'RandomForest Classifier'},\n",
    "        {'model': GradientBoostingClassifier(n_estimators=100,\n",
    "                                             criterion='mse',\n",
    "                                             learning_rate=0.1,\n",
    "                                             max_depth=4,\n",
    "                                             random_state=7), 'name': 'GradientBoost Classifier'}\n",
    "    ]\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to hold the train, validation and test accuracies of all the models that we evaluate\n",
    "result_df = pd.DataFrame(columns=['train accuracy', 'k-fold-cv mean', 'k-fold-cv std', 'test_accuracy'])\n",
    "\n",
    "# Function to evaluate each model against train, validation and test data by looping through all the models that \n",
    "# construct_models_list function returns. It uses K-Fold cross validation\n",
    "def evaluate_models(xtrain, xval, ytrain, yval, xtest, ytest, model_name_prefix, result_df):\n",
    "    start_time = time.process_time()\n",
    "    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "    # get the list of models to evaluate\n",
    "    models = construct_models_list()\n",
    "    # loop through each model\n",
    "    for model_obj in models:\n",
    "        # getting the model instance\n",
    "        model = model_obj['model']\n",
    "        name = model_name_prefix+'_'+model_obj['name']\n",
    "        # fit the model against train data\n",
    "        model.fit(xtrain, ytrain)\n",
    "        # compute the train accuracy\n",
    "        train_accuracy = model.score(xtrain, ytrain)\n",
    "        # evaluate the model using K-Fold cross validation\n",
    "        cv_result = cross_val_score(model, xval, yval, cv=kfold, n_jobs=4)\n",
    "        # print the result of cross validation\n",
    "        print(cv_result)\n",
    "        # compute the test accuracy\n",
    "        test_accuracy = model.score(xtest, ytest)\n",
    "        # store train accuracy, cross validation results mean, standard deviation and test accuracy for each model name\n",
    "        result_df.loc[name] = [train_accuracy, cv_result.mean(), cv_result.std(), test_accuracy]\n",
    "        # return the result_df\n",
    "    total_time_taken = time.process_time() - start_time\n",
    "    # Logging the time taken for models evaluation, just for informational purpose\n",
    "    print('\\nTime taken to evaluate models with {} data {}'.format(model_name_prefix, total_time_taken))\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10248, 1000)\n",
      "y_train shape: (10248,)\n",
      "X_val shape: (1318, 1000)\n",
      "y_val shape: (1318,)\n",
      "X_test shape: (3074, 1000)\n",
      "y_test shape: (3074,)\n"
     ]
    }
   ],
   "source": [
    "# Split the count vectorized data into train, validation and test\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split(count_vectorized_tweets,y)\n",
    "# Print the shape of the data\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81060606 0.75757576 0.75       0.70454545 0.77272727 0.66666667\n",
      " 0.6969697  0.68939394 0.78625954 0.7480916 ]\n",
      "[0.72727273 0.62878788 0.71969697 0.70454545 0.70454545 0.61363636\n",
      " 0.64393939 0.62121212 0.70229008 0.67938931]\n",
      "[0.67424242 0.60606061 0.62878788 0.65909091 0.66666667 0.57575758\n",
      " 0.60606061 0.58333333 0.74045802 0.67175573]\n",
      "[0.78787879 0.6969697  0.71969697 0.68181818 0.74242424 0.63636364\n",
      " 0.65909091 0.66666667 0.77099237 0.7480916 ]\n",
      "\n",
      "Time taken to evaluate models with CountVectorizer data 143.55333099999984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>k-fold-cv mean</th>\n",
       "      <th>k-fold-cv std</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_Logistic Regressor</th>\n",
       "      <td>0.842799</td>\n",
       "      <td>0.738284</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.781718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_DecisionTree Classifier</th>\n",
       "      <td>0.693111</td>\n",
       "      <td>0.674532</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.676643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_RandomForest Classifier</th>\n",
       "      <td>0.624610</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>0.048064</td>\n",
       "      <td>0.631100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_GradientBoost Classifier</th>\n",
       "      <td>0.778884</td>\n",
       "      <td>0.710999</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>0.736174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train accuracy  k-fold-cv mean  \\\n",
       "CountVectorizer_Logistic Regressor              0.842799        0.738284   \n",
       "CountVectorizer_DecisionTree Classifier         0.693111        0.674532   \n",
       "CountVectorizer_RandomForest Classifier         0.624610        0.641221   \n",
       "CountVectorizer_GradientBoost Classifier        0.778884        0.710999   \n",
       "\n",
       "                                          k-fold-cv std  test_accuracy  \n",
       "CountVectorizer_Logistic Regressor             0.044372       0.781718  \n",
       "CountVectorizer_DecisionTree Classifier        0.041227       0.676643  \n",
       "CountVectorizer_RandomForest Classifier        0.048064       0.631100  \n",
       "CountVectorizer_GradientBoost Classifier       0.048195       0.736174  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the models with CounterVectorized data and storing the results in result_df dataframe\n",
    "result_df = evaluate_models(X_train, X_val, y_train, y_val, X_test, y_test, 'CountVectorizer', result_df)\n",
    "# Displaying result_df dataframe\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "` Among all the models, logistic regression is giving better test accuracy of 78.1% for counter vectorized data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=7)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating logistic regression. Since its a multiclass problem using multi_class='multinomial', solver='lbfgs' for logistic regression\n",
    "logit = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=7)\n",
    "# Fitting the logistic regression with counter vectorized data\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting for test data\n",
    "y_predict = logit.predict(X_test)\n",
    "\n",
    "# Creating confusion matrix using actual and predicted values\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "# Creating a dataframe using confuxion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=[0,1,2], columns=[0,1,2])\n",
    "# Plotting confusion matrix in a heatmap\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1939\n",
      "           1       0.61      0.56      0.58       650\n",
      "           2       0.72      0.62      0.67       485\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.73      0.69      0.71      3074\n",
      "weighted avg       0.78      0.78      0.78      3074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the classification report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "<ol>\n",
    "    <li>The model has 84% precision and 90% recall for negative sentiments, 61% precision and 56% recall for neutral sentimants. Similarly 72% precision and 62% recall for postive sentiments </li>\n",
    "    <li>The model overall accuracy is 78%</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10248, 1000)\n",
      "y_train shape: (10248,)\n",
      "X_val shape: (1318, 1000)\n",
      "y_val shape: (1318,)\n",
      "X_test shape: (3074, 1000)\n",
      "y_test shape: (3074,)\n"
     ]
    }
   ],
   "source": [
    "# Split the tfidf vectorized data into train, validation and test\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split(tfidf_vectorized_tweets,y)\n",
    "# Print the shape of the data\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78787879 0.71969697 0.72727273 0.72727273 0.75       0.68181818\n",
      " 0.70454545 0.67424242 0.83206107 0.72519084]\n",
      "[0.73484848 0.67424242 0.72727273 0.68939394 0.6969697  0.58333333\n",
      " 0.6969697  0.62878788 0.73282443 0.70992366]\n",
      "[0.67424242 0.60606061 0.62878788 0.65909091 0.66666667 0.57575758\n",
      " 0.60606061 0.59090909 0.74045802 0.67938931]\n",
      "[0.79545455 0.70454545 0.74242424 0.71212121 0.75757576 0.59848485\n",
      " 0.67424242 0.64393939 0.79389313 0.73282443]\n",
      "\n",
      "Time taken to evaluate models with TfidfVectorizer data 145.9685629999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>k-fold-cv mean</th>\n",
       "      <th>k-fold-cv std</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_Logistic Regressor</th>\n",
       "      <td>0.842799</td>\n",
       "      <td>0.738284</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.781718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_DecisionTree Classifier</th>\n",
       "      <td>0.693111</td>\n",
       "      <td>0.674532</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.676643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_RandomForest Classifier</th>\n",
       "      <td>0.624610</td>\n",
       "      <td>0.641221</td>\n",
       "      <td>0.048064</td>\n",
       "      <td>0.631100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer_GradientBoost Classifier</th>\n",
       "      <td>0.778884</td>\n",
       "      <td>0.710999</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>0.736174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_Logistic Regressor</th>\n",
       "      <td>0.828064</td>\n",
       "      <td>0.732998</td>\n",
       "      <td>0.045054</td>\n",
       "      <td>0.782368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_DecisionTree Classifier</th>\n",
       "      <td>0.710870</td>\n",
       "      <td>0.687457</td>\n",
       "      <td>0.045867</td>\n",
       "      <td>0.680221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_RandomForest Classifier</th>\n",
       "      <td>0.629098</td>\n",
       "      <td>0.642742</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.636630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer_GradientBoost Classifier</th>\n",
       "      <td>0.793228</td>\n",
       "      <td>0.715551</td>\n",
       "      <td>0.059984</td>\n",
       "      <td>0.740403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          train accuracy  k-fold-cv mean  \\\n",
       "CountVectorizer_Logistic Regressor              0.842799        0.738284   \n",
       "CountVectorizer_DecisionTree Classifier         0.693111        0.674532   \n",
       "CountVectorizer_RandomForest Classifier         0.624610        0.641221   \n",
       "CountVectorizer_GradientBoost Classifier        0.778884        0.710999   \n",
       "TfidfVectorizer_Logistic Regressor              0.828064        0.732998   \n",
       "TfidfVectorizer_DecisionTree Classifier         0.710870        0.687457   \n",
       "TfidfVectorizer_RandomForest Classifier         0.629098        0.642742   \n",
       "TfidfVectorizer_GradientBoost Classifier        0.793228        0.715551   \n",
       "\n",
       "                                          k-fold-cv std  test_accuracy  \n",
       "CountVectorizer_Logistic Regressor             0.044372       0.781718  \n",
       "CountVectorizer_DecisionTree Classifier        0.041227       0.676643  \n",
       "CountVectorizer_RandomForest Classifier        0.048064       0.631100  \n",
       "CountVectorizer_GradientBoost Classifier       0.048195       0.736174  \n",
       "TfidfVectorizer_Logistic Regressor             0.045054       0.782368  \n",
       "TfidfVectorizer_DecisionTree Classifier        0.045867       0.680221  \n",
       "TfidfVectorizer_RandomForest Classifier        0.047731       0.636630  \n",
       "TfidfVectorizer_GradientBoost Classifier       0.059984       0.740403  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the models with Tfidfvectorized data and storing the results in result_df dataframe\n",
    "result_df = evaluate_models(X_train, X_val, y_train, y_val, X_test, y_test, 'TfidfVectorizer', result_df)\n",
    "# Displaying result_df dataframe\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "` Among all the models, logistic regression is giving better test accuracy of 78.2% for tfidf vectorized data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=7)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating logistic regression, Since its a multiclass problem using multi_class='multinomial', solver='lbfgs' for logistic regression\n",
    "logit = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=7)\n",
    "# Fitting the logistic regression with tfidf vectorized data\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting for test data\n",
    "y_predict = logit.predict(X_test)\n",
    "\n",
    "# Creating confusion matrix using actual and predicted values\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "# Creating a dataframe using confuxion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=[0,1,2], columns=[0,1,2])\n",
    "# Plotting confusion matrix in a heatmap\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1939\n",
      "           1       0.64      0.49      0.55       650\n",
      "           2       0.76      0.57      0.65       485\n",
      "\n",
      "    accuracy                           0.78      3074\n",
      "   macro avg       0.74      0.66      0.69      3074\n",
      "weighted avg       0.77      0.78      0.77      3074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the classification report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "\n",
    "<ol>\n",
    "    <li>The model has 82% precision and 93% recall for negative sentiments, 64% precision and 49% recall for neutral sentimants. Similarly 76% precision and 57% recall for postive sentiments </li>\n",
    "    <li>The model overall accuracy is 78%</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<ol>\n",
    "    <li> We have used the tweets data that has the sentiment classified into negative, neutral and positive</li>\n",
    "    <li> We have preprocessed the text by removing html tags, tokenized the text, removed accented characters, removed numbers, removed any special characters, removed punctuations, replaced contractions and stop words. We have converted the text into lower case and performed lemmatization of the tokens in a sentence and finally joined them to form the sentence back </li>\n",
    "    <li> We did count vectorization and tfidf vectorization taking cleansed/preprocessed text as input. </li>\n",
    "    <li> Count vectorized vector has values 0 and 1 where as tfidf vectorized matrix has float values between 0 and 1</li>\n",
    "    <li> We fit both vectorized data against multiple machine learning classifier models. In both the cases, LogisticRegression seems performing well for the data.</li>\n",
    "    <li> The test accuracy is almost the same with both tfidf and count vectorized data, with very minute increase when using tfidf vectorized data.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
